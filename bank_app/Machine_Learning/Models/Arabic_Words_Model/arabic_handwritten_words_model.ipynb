{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a7f11c6",
   "metadata": {},
   "source": [
    "## Loading the arabic words dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1dec0",
   "metadata": {},
   "source": [
    "*    **class_mode=\"categorical\"**: 2D output (aka. list of numbers of length N), [0, 0, 1, 0], which is a one-hot encoding (only one number is 1/ \"hot\") representing the donkey. This is for mutually exclusive labels. A dog cannot be a cat, a human is not a dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afdac2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4832 images belonging to 6 classes.\n",
      "Found 848 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# load train data\n",
    "train_path = r\"C:\\Users\\ADEM\\Desktop\\ESPRIT_Education\\4er\\PI DS\\image preprocessing\\Data Augmentation\\arabic dataset\\train\" \n",
    "val_path = r\"C:\\Users\\ADEM\\Desktop\\ESPRIT_Education\\4er\\PI DS\\image preprocessing\\Data Augmentation\\arabic dataset\\val\" \n",
    "# create a new generator\n",
    "datagen = ImageDataGenerator(rotation_range = 3, #random rotation of 0 to 3 degrees\n",
    "                            width_shift_range=0.05,\n",
    "                            height_shift_range=0.05,\n",
    "                            shear_range = 0.01,\n",
    "                            zoom_range = 0.01,        \n",
    "                            horizontal_flip = False,\n",
    "                            vertical_flip=False,\n",
    "                            fill_mode=\"constant\",cval=255)\n",
    "\n",
    "train = datagen.flow_from_directory(train_path, \n",
    "                                    class_mode=\"categorical\", \n",
    "                                    shuffle=False,  \n",
    "                                    target_size=(256, 256))\n",
    "# load val data\n",
    "val = datagen.flow_from_directory(val_path, \n",
    "                                  class_mode=\"categorical\", \n",
    "                                  shuffle=False,  \n",
    "                                  target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de71f5d",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802e5afe",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    "   *  starting with an  **input layer**\n",
    "  \n",
    "   *  **bloc1** :   \n",
    "   \n",
    "       *  a single **convolutional layer** with a small ***filter size (5,5)** and a modest number of nodes(filters) ***(15)***\n",
    "       *  the result is a two-dimensional array of output values that represent a filtering of the input that maps the detected features in what we call a ***“feature map“***\n",
    "       *  ***Multiple Filters*** <==> learning multiple features in parallel for a given input.\n",
    "       *  ***Multiple Layers*** <==> The stacking of conv layers allows a hierarchical decomposition of the input        \n",
    "       *  followed by a **max pooling layer**\n",
    "       *  operates on each feature map separately to **create a new set** of the same number of pooled feature maps\n",
    "       *  much like a filter to be applied to feature maps, ***almost always 2×2*** pixels applied with a stride of 2 pixels, and will always reduce the size of each feature map by a factor of pool size\n",
    "  \n",
    "   *  **bloc2** :   \n",
    "   \n",
    "       *  a single **convolutional layer** with a small ***filter size (5,5)** and a modest number of nodes(filters) ***(30)*** \n",
    "       *  followed by a **max pooling layer**\n",
    "       *  operates on each feature map separately to **create a new set** of the same number of pooled feature maps      \n",
    "  \n",
    "   *  **bloc3** :   \n",
    "   \n",
    "       *  a single **convolutional layer** with a small ***filter size (3,3)** and a modest number of nodes(filters) ***(40)*** \n",
    "       *  followed by a **max pooling layer**\n",
    "       *  operates on each feature map separately to **create a new set** of the same number of pooled feature maps             \n",
    " \n",
    "         \n",
    "         \n",
    "   *  then be **flattened** to provide features to the classifier.  \n",
    "     \n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7409baf",
   "metadata": {},
   "source": [
    "####  The Back-End (Classifer):  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928031db",
   "metadata": {},
   "source": [
    "  \n",
    "   *  ***multi-class classification task***\n",
    "       *  require an **output layer with 6 nodes** in order to predict the probability distribution of an image belonging to each of the 6 classes.\n",
    "       *  require the use of a ***softmax activation function*** (probability function)\n",
    "       *  we can add a ***60 nodes dense layer*** to interpret the features.\n",
    "       *  All layers will use the ***ReLU activation function*** and the He weight initialization scheme for the simple reason is that we have the input data in image formats which means ***all values of the image matrix will be from 0 to 255**, and to avoid problems that can accures after conv layer or pooling we will be ***replacing all negative values with 0 and keep all the remaining values as they are***.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3872be",
   "metadata": {},
   "source": [
    "#### Optimization :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8e846",
   "metadata": {},
   "source": [
    "*  stochastic gradient descent optimizer \n",
    "      *  an optimization algorithm \n",
    "      *  The job of the algorithm is to find a set of internal model parameters that perform well against some performance measure such as logarithmic loss or mean squared error.\n",
    "*  learning rate of 0.01 \n",
    "*  a momentum of 0.9\n",
    "*  and \"categorical cross-entropy\" for the  loss function\n",
    "*  to accelerate the learning of a model : ***Batch normalization*** after convolutional and fully connected layers, designed to automatically standardize the inputs to a layer and has the effect of **dramatically accelerating the training process** of a neural network, the layer will keep track of statistics for each input variable and use them to standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130ab559",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "def define_model():\n",
    "    # build a sequential model\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(256, 256, 3)))\n",
    "    \n",
    "    # 1st conv block\n",
    "    model.add(Conv2D(15, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "    \n",
    "    # 2nd conv block\n",
    "    model.add(Conv2D(30, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    # 3rd conv block\n",
    "    model.add(Conv2D(40, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "    model.add(BatchNormalization())\n",
    "    # ANN block\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=60, activation='relu'))\n",
    "    model.add(Dense(units=60, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    # output layer\n",
    "    model.add(Dense(units=6, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "\n",
    "# fit on data for 30 epochs\n",
    "#model.fit_generator(train, epochs=30, validation_data=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61b509e",
   "metadata": {},
   "source": [
    "## Model Running Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e40a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using k-fold cross-validation\n",
    "def run_model(train, val):\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # fit model\n",
    "    run = model.fit(train, batch_size=32, epochs=10, validation_data=val, verbose=1) \n",
    "    #verbose: 0 for no logging to stdout, 1 for progress bar logging, 2 for one log line per epoch.\n",
    "    # save model\n",
    "    model.save('final_Handwritten_words_arabic_model.h5') \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db6fbe",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfa22c",
   "metadata": {},
   "source": [
    "**this cell bellow** dedicated for testing  \n",
    "when runing the cell it will take about **18mnit** to be done, and for that i turned it into mardkown cell to avoid long runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f2518d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 100s 662ms/step - loss: 0.7886 - accuracy: 0.7550 - val_loss: 0.2389 - val_accuracy: 0.9222\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 100s 663ms/step - loss: 0.0391 - accuracy: 0.9921 - val_loss: 0.0373 - val_accuracy: 0.9847\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 101s 670ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.0149 - val_accuracy: 0.9929\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 100s 660ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.0056 - val_accuracy: 0.9988\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 100s 665ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0049 - val_accuracy: 0.9988\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 101s 666ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0038 - val_accuracy: 0.9988\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 100s 664ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 100s 662ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0017 - val_accuracy: 0.9988\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 101s 669ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0106 - val_accuracy: 0.9988\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 100s 665ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 1.8815e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#run the test harness for evaluating a model\n",
    "def run_test_arabic_model():\n",
    "    # evaluate model\n",
    "    runs = run_model(train, val)\n",
    "\n",
    "#entry point, run the test harness\n",
    "run_test_arabic_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}